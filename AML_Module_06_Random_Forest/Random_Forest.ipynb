{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Random Forest Classifier\n",
                "\n",
                "**Author: Jessica Cervi**\n",
                "\n",
                "**Expected time = 2 hours**\n",
                "\n",
                "**Total points = 75 points**\n",
                " \n",
                " \n",
                " \n",
                "## Assignment Overview\n",
                "\n",
                "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. You must adopt a data scientist's mindset when completing this assignment. **Remember to run your code from each cell before submitting your assignment.** Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting it. You should view your Vocareum submission as if you are delivering a final project to your manager or client. \n",
                "\n",
                "***Vocareum Tips***\n",
                "- Do not add arguments or options to functions unless asked specifically. This will cause an error in Vocareum.\n",
                "- Do not use a library unless you are explicitly asked in the question.\n",
                "- You can download the Grading Report after submitting the assignment. It will include the feedback and hints on incorrect questions. \n",
                "\n",
                "\n",
                "### Learning Objectives\n",
                "\n",
                "- Examine the class distribution in a classification problem \n",
                "- Handle the categorical features using \"get dummies\" \n",
                "- Investigate class splits using the Gini index\n",
                "- Determine baseline accuracy for classifiers \n",
                "- Organize grid search hyperparameters in tree models \n",
                "\n",
                "\n",
                "\n",
                "## Index: \n",
                "\n",
                "#### Random Forest Classifier\n",
                "\n",
                "- [Question 1](#q1)\n",
                "- [Question 2](#q2)\n",
                "- [Question 3](#q3)\n",
                "- [Question 4](#q4)\n",
                "- [Question 5](#q5)\n",
                "- [Question 6](#q6)\n",
                "- [Question 7](#q7)\n",
                "- [Question 8](#q8)\n",
                "- [Question 9](#q9)\n",
                "- [Question 10](#q10)\n",
                "- [Question 11](#q11)\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "This assignment uses a variety of decision tree based classifiers to attempt prediction of whether or not a customer will default on their loans. Our data comes from [the UCI machine learning Repository](https:\/\/archive.ics.uci.edu\/ml\/index.php) on [default of credit card clients](https:\/\/archive.ics.uci.edu\/ml\/datasets\/default+of+credit+card+clients#)  \n",
                "\n",
                "Activities will include:  \n",
                "- Manipulating DataFrames  \n",
                "- Visualizing data  \n",
                "- Calculating impurity measures  \n",
                "- Using sklearn's tree and forest models  \n",
                "- Evaluating the effects of hyperparameter tuning  \n",
                "\n",
                "\n",
                "**Motivation**: Decision Trees and Forests offer easy to understand yet fairly advanced models with a variety of hyperparameters to increase or decrease complexity to tune between bias and variance\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Random Forest Classifier\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Importing the data set and exploratory data analysis\n",
                "\n",
                "This assignment uses a variety of decision tree-based classifiers to attempt a prediction of whether or not a customer will default on their loans. Our data comes from [the UCI machine learning Repository](https:\/\/archive.ics.uci.edu\/ml\/index.php) on [default of credit card clients](https:\/\/archive.ics.uci.edu\/ml\/datasets\/default+of+credit+card+clients#).\n",
                "\n",
                "In particular, using a given a number of personal variables - sex, education, marriage status, age; and recent payment history, we will attempt to predict whether or not a customer will default in the next month.  \n",
                "\n",
                "Before coding an algorithm, we will take a look at our data using 'Python's 'pandas'. For visualizations, we'll use 'matplotlib'.\n",
                "\n",
                "Let's import the necessary libraries and load the datasets. We will be using the pandas 'pd.read_excel()' function. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Import necessary packages\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "%matplotlib inline\n",
                "\n",
                "\n",
                "# Read in Data\n",
                "df = pd.read_excel(\".\/data\/credit_card_data.xls\", header = 1)\n",
                "\n",
                "df.rename(columns = {\"PAY_0\":\"PAY_1\"}, inplace = True) #renaming mis-named column"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We begin by performing some basic exploratory data analysis by using the function 'head()' and the attribute 'columns'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " \n",
                "\n",
                "- X1: Amount of the given credit (NT dollar): it includes both, the individual consumer credit and his\/her family (supplementary) credit. \n",
                "- X2: Gender (1 = male; 2 = female). \n",
                "- X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
                "- X4: Marital status (1 = married; 2 = single; 3 = others). \n",
                "- X5: Age (year). \n",
                "- X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
                "- X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. \n",
                "- X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
                "\n",
                "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Next, it is always important to check whether we have any null values on our dataframe. We can do so by using the command '.info()'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print(\"Data Shape: \" , df.shape, \"\\n\")\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Great, it appears that there aren't any null in our dataframe.\n",
                "   \n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q1'><\/a>\n",
                "\n",
                "### Question 1:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "The 'default payment next month' variable will be the target used for classification. Investigate its distribution for the question below.\n",
                "\n",
                "Assign an int to the variable 'ans0' corresponding to the total number of non-default records.\n",
                "Assign an int to the variable 'ans1' corresponding to the total number of default records\n",
                "\n",
                "Note a \"0\" in the 'default payments next month' column means \"non-default\" and a 1 means \"default\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "\n",
                "### YOUR ANSWERS BELOW\n",
                "\n",
                "ans0 = None\n",
                "ans1 = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 01",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We observe that the proportion of default and non-default records means we are dealing with unbalanced classes."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "#### Investigating the Features\n",
                "\n",
                "Now, we will investigate some features trends using the function 'value_count()'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "df['EDUCATION'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note: The code-book from where we have downloaded the dataset, describes the education variable having only four values (1-4). However, there are seven values (0-6).  \n",
                "In some cases, this might be grounds to throw out the unknown values 0,5, and 6. For now, we will leave them as is, assuming that they have some (unknown to us) meaning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "df['MARRIAGE'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note: Again, the code-book describes only three values for marriage (1-3). However, here, \"0\" also appears. Given what we saw above, we might assume that \"0\" in these categorical variables is functionally the \"null\" value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "df['SEX'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note: A slight imbalance exists in the representation of men and women, with women making up a little over 60% of our observations. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "df['PAY_1'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "#### Investigate relationship between the variables - 'Pay', 'Bill_amt', and 'Pay_amt'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "for i in [-2,-1,0,1,2,8]:\n",
                "    print(df[df['PAY_1']==i][['PAY_1','BILL_AMT1','PAY_AMT1']].head(8), \"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "It is unclear exactly how these 'PAY_1','BILL_AMT1', and 'PAY_AMT1' variables work and how they are related to each other. Possibly they should be treated as categorical data instead of discrete and interval data, but, for our purposes, we keep them as interval data.\n",
                "\n",
                "Below, we define a function to create histograms for the 'PAY_1','BILL_AMT1', and 'PAY_AMT1' variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Define function for creating histograms\n",
                "def pay_hist(df, cols, ymax):\n",
                "    plt.figure(figsize= (10,7)) # define fig size\n",
                "    \n",
                "    for index, col in enumerate(cols): # For each column passed to function\n",
                "        plt.subplot(2,3, index +1) # plot on new subplot\n",
                "        plt.ylim(ymax = ymax) # standardize ymax\n",
                "        plt.hist(df[col]) # create hist\n",
                "        plt.title(col) # title with column names\n",
                "    plt.tight_layout(); # make sure titles don't overlap\n",
                "\n",
                "pay_cols = [\"PAY_\"+str(n) for n in range(1,7)]\n",
                "pay_amt_cols = ['PAY_AMT' + str(n) for n in range(1,7)]\n",
                "bill_amt_cols = ['BILL_AMT' + str(n) for n in range(1,7)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pay_hist(df, pay_cols, 20000)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note: Clearly, \"0\" is the majority class for all of the \"PAY\" variables. However, we recall that from the code-book, it is unclear what \"0\" means."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pay_hist(df, pay_amt_cols, 20000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "df_no_0_pay_amt_1 = df[df[\"PAY_AMT1\"]!=0]\n",
                "df_no_0_pay_amt_1[\"PAY_AMT1\"].hist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We notice that even taking out all the PAY_AMT of 0, most payments stay close to 0 with a long tail.\n",
                "\n",
                "When dealing with skewed data, log transformation (used above) or $\\sqrt[4]{x}$ transformations (which automatically deals with 0s), can become useful. Below, we see that most of the repayment amounts are in the thousands of dollars after using log transformation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "log_pay_amt1 = np.log10(df_no_0_pay_amt_1[\"PAY_AMT1\"])\n",
                "plt.hist(log_pay_amt1)\n",
                "plt.title(\"Log10-Transformed values for 'PAY_AMT1' (Excluding 0s)\");"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pay_hist(df, bill_amt_cols, 23000)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Preprocessing\n",
                "\n",
                "Currently, the coding used in the variable 'SEX' is 2 for 'female' and 1 for 'male'. We want 'SEX' to be in binary code. So, we will change the column name to 'FEMALE' and subtract 1 from each entry. This way, 1 will correspond to 'female' and 0 to 'male'.\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q2'><\/a>\n",
                "\n",
                "### Question 2:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Change the values of the column 'SEX' to 0 and 1. Next, rename the column 'SEX' to 'FEMALE' and the column 'default payment next month' to 'default'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "\n",
                "### YOUR ANSWERS BELOW\n",
                "\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 02",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we observe that both 'EDUCATION' and 'MARRIAGE' are categorized with multiple options. The function 'pd.get_dummies()' will allow us to create n-1 binary features to encode the n categories.  \n",
                "\n",
                "\n",
                "\n",
                "#### Note regarding `get_dummies()`\n",
                "\n",
                "Always be careful in using the function 'pd.get_dummies()'. It is NOT appropriate in many machine learning applications.  \n",
                "\n",
                "Example: Currently we have the values 0-6 under the 'EDUCATION' feature. Running the  function 'pd.get_dummies()' on the test set would add 6 columns. Instead, the training set would only have 5 columns added from that action. Therefore, the fit model would not know how to deal that new feature\/category.  \n",
                "\n",
                "Here, the function 'pd.get_dummies()'used for the sake of simplicity.\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q3'><\/a>\n",
                "\n",
                "### Question 3:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Rename the columns 'EDUCATION' and 'MARRIAGE' as 'EDU' and 'MAR', respectivly. Next, encode 'EDUCATION' AND 'MARRIAGE'  by using the function 'get_dummies()' and remove the original 'EDUCATION' and 'MARRIAGE' columns.\n",
                "\n",
                "**HINT:** In 'get_dummies()', set 'prefix = pre, drop_first = True'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "\n",
                "### YOUR ANSWERS BELOW\n",
                "\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 03",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q4'><\/a>\n",
                "\n",
                "### Question 4:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Why are 'dummy' variables necessary?\n",
                "\n",
                "- a) It helps to expand the number of features.\n",
                "- b) It deals with multi-class categorical data unlike models.\n",
                "- c) It translates categorical data into quantitative data.\n",
                "\n",
                "Assign a character corresponding to your choice as string to 'ans4'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans4 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 04",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"part2\"><\/a>\n",
                "## Trees and Forests: Introduction\n",
                "\n",
                "\n",
                "Given a target variable (categorical or continuous), a decision tree iteratively splits the data at the value that creates the greatest separation among the target variable.\n",
                "\n",
                "For example, let the target variable on a dataset of professional basketball players is league: NBA and WNBA. The available features are height and weight.  \n",
                "\n",
                "Split 1: For the players greater than 6'8\" tall (which is very rare), a decision tree might split the data at the height of 6'8\", 6'7\", or 6'6\" and predict for a basketball player over 6'6\", plays in the NBA.  \n",
                "\n",
                "Split 2: For the players shorter than 6'6\", the decision tree might split the data again at 5'10\" and predict for the basketball players under 5'10\", play in the WNBA.  \n",
                "\n",
                "Split 3: For the players between 5'10\" and 6'6\", maybe the tree might discriminate on weight, predicting that all those players who weigh more than 180 Lbs., play in the NBA.  \n",
                "\n",
                "The resulting tree could be visualized as below."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "![DTExample](.\/assets\/DTExample.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Depth\n",
                "\n",
                "The above tree has a depth of 2. \n",
                "\n",
                "The maximum depth to which a tree is allowed to grow can be specified using the function 'max_depth' from 'sklearn'. By default, 'max_depth' is set to 'None' that means the tree will grow until all leaves (terminal nodes) are pure, or until other user-specified criteria are met. Importantly, the function 'max_depth' can impact the amount of time it takes to build a tree (this becomes especially important when starting to work with forests.)  \n",
                "\n",
                "### Splitting\n",
                "\n",
                "The splits in the above trees were determined intuitively. Thankfully, the decision trees do not make their decisions using intuition. In the 'sklearn' package, two splitting criteria are available for classifiers-'Gini' and 'Entropy'. In general, 'Gini' favors splitting larger partitions, whereas 'Entropy' favors splitting of smaller groups that are of a single class. \n",
                "\n",
                "For more information about the 'Gini' and the 'Entropy' classifiers visit: [More on Gini\/Entropy](http:\/\/www.learnbymarketing.com\/481\/decision-tree-flavors-gini-info-gain\/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Gini and Entropy Calculations\n",
                "\n",
                "<table><tr><td><img src='.\/assets\/choc.png' style=\"width: 70%;\"><\/td><td><img src='.\/assets\/choc2.png' style=\"width: 70%;\"><\/td><\/tr><\/table>  \n",
                "\n",
                "\n",
                "Above, we have split the dataset regarding good chocolate and bad chocolate.  \n",
                "\n",
                "In the next question, you will be asked to calculate the Gini impurity.\n",
                "\n",
                "When 'American == True', we have 175 good chocolates and 330 bad chocolates. When 'American == False', there are 200 good chocolates and 120 bad chocolates.\n",
                "\n",
                "When 'German == True', we have 175 good chocolates and 330 bad chocolates. When 'German == False', there are 200 good chocolates and 120 bad chocolates.\n",
                "\n",
                "As a reminder, the Gini index for a node can be computed via:\n",
                "\n",
                "$$1- \\sum_{j=1}^n p^2_j,$$\n",
                "where $n$ are the classes and $p_j$ is the frequency of class j in that node.  \n",
                "\n",
                "Finally, the indexes for each of these nodes are weighted by the proportion of data at each node, then summed.  \n",
                "Remember, Gini indicies closer to 0 are purer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q5'><\/a>\n",
                "\n",
                "### Question 5:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Calculate the Gini impurity for the split on 'American'.\n",
                "\n",
                "Assign float answer to the variable 'ans5',  round your answer to 4 decimal places."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans5 = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 05",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q6'><\/a>\n",
                "\n",
                "### Question 6:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Calculate the Gini impurity for the split on 'German'.\n",
                "\n",
                "Assign float answer to the variable 'ans6',  round your answer to 4 decimal places."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans6 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 06",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q7'><\/a>\n",
                "\n",
                "### Question 7:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "According to the Gini values calcualted above, which split is better?\n",
                "\n",
                "- a) American\n",
                "- b) German\n",
                "Assign character associated with your choice as string to 'ans7'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans7 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 07",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Forests\n",
                "\n",
                "'Forests' are the collections of decision trees that are designed to protect against over-fitting.  \n",
                "\n",
                "A single decision tree (particularly one that is allowed to grow to any depth), may be prone to overfitting. Algorithmically, the tree is designed to continue to make splits until it has completely classified all of the available data, and\/or exhausted every possible split for some very high level of complexity. A tree might be 'pruned' (by setting max_depth) to protect against over fitting, but, we can use a 'forest' of trees instead.  \n",
                "\n",
                "### Baseline accuracy\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q8'><\/a>\n",
                "\n",
                "### Question 8:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Going back to our credit card example, assume we are predicting default\/not-default.\n",
                "What percent (between 0 and 100) of observations would be correctly predicted if the majority class was predicted every time? In other words, what is the baseline accuracy?\n",
                "\n",
                "Assign integer value to 'ans8'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans8=None \n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 08",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Decision trees in sklearn\n",
                "\n",
                "Like all other machine learning algorithms that we have seen so far, decision trees are also implemented automatically in 'sklearn'.\n",
                "\n",
                "For a more complete description of how to implement decision trees  in `sklearn` you can visit the [decision trees in `sklearn` - Documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html)  \n",
                "\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q9'><\/a>\n",
                "\n",
                "### Question 9:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "\n",
                "Split our data into `X_train`, `X_test`, `y_train` and `y_test` sets by setting, as target, the column `default`. Set the `test_size =.3` and  `random_state = 1738`.\n",
                "\n",
                "Use the function `DecisionTreeClassifier` from `sklearn` to instantiate the classifier `dt`.\n",
                "\n",
                "Use the function `BaggingClassifier` from `sklearn` to instantiate the classifier `bag`.\n",
                "\n",
                "Use the function `RandomForestClassifier` from `sklearn` to instantiate the classifier `rf`.\n",
                "\n",
                "Use the function `ExtraForestClassifier` from `sklearn` to instantiate the classifier `et`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "X_train = None\n",
                "X_test = None\n",
                "y_train = None\n",
                "y_test = None\n",
                "dt = None\n",
                "bag = None\n",
                "rf = None\n",
                "et = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 09",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Next, we look at performance of the different classifiers using the default parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "dt.fit(X_train, y_train)\n",
                "print(\"Decision Tree: \\n\", classification_report(y_test, dt.predict(X_test)), \"\\n\")\n",
                "\n",
                "\n",
                "print(\"-----------\")\n",
                "\n",
                "bag.fit(X_train, y_train)\n",
                "print(\"Bagging: \\n\", classification_report(y_test, bag.predict(X_test)), \"\\n\")\n",
                "\n",
                "\n",
                "\n",
                "print(\"-----------\")\n",
                "\n",
                "rf.fit(X_train, y_train)\n",
                "print(\"Random Forest: \\n\", classification_report(y_test, rf.predict(X_test)), \"\\n\")\n",
                "\n",
                "print(\"------------\")\n",
                "\n",
                "et.fit(X_train, y_train)\n",
                "print(\"Extra Trees: \\n\", classification_report(y_test, et.predict(X_test)), \"\\n\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q10'><\/a>\n",
                "\n",
                "### Question 10:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Are all predictions in this dataset equal in business value? In other words, is it correct to predict a 'default' prediction as valuable as a 'non-default' one?\n",
                "- a) Equal values\n",
                "- b) Unequal values\n",
                "\n",
                "Assign string associated with your choice to 'ans9'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans9 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 10",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Hyper Parameter Tuning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "It appears that both the Random Forest and the Extra Trees perform in a similarly effective manner. For this section, we will try to increase the performance of the Random Forest by tuning a couple of hyperparameters, namely, criterion and estimators.\n",
                "\n",
                "We are more interested in forecasting defaults than non-defaults. So, we will optimize the recall of defaults, where recall is the proportion of defaults predicted over total defaults.  \n",
                "\n",
                "The code cell below will not run on Vocareum due to processing constraints, thus the output is copied below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# %%time\n",
                "# from sklearn.metrics import recall_score\n",
                "# criterion = ['gini', 'entropy']\n",
                "# n_estimators = [5,10,20, 50, 100]\n",
                "# scores = dict()\n",
                "# i = 0\n",
                "# for c in criterion:\n",
                "#     for e in n_estimators:\n",
                "#         rf = RandomForestClassifier(n_estimators = e, criterion = c, random_state = 1738)\n",
                "#         rf.fit(X_train, y_train)\n",
                "#         scores[i] = {'recall':recall_score(y_test, rf.predict(X_test)), 'trees' :e, \"crit\":c}\n",
                "#         i+=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# pd.DataFrame(scores).T"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "![recallScores](.\/assets\/recallScores3.PNG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q11'><\/a>\n",
                "\n",
                "### Question 11:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "According to the output shown in the picture above, how many trees did the model with the best recall score featured? Assign integer value to the variable 'ans10'.\n",
                "\n",
                "Which splitting method?\n",
                "- a) entropy \n",
                "- b) gini\n",
                "Assign the character corresponding to your selection as a string to the variable 'ans11'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR ANSWER BELOW\n",
                "\n",
                "ans10 = None\n",
                "ans11 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 11",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We suspect that 'RandomForestClassifier' will perform best using 'Gini' splittling with somewhere around 5 trees.\n",
                "\n",
                "Let's see what happens by tuning some paramenters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# n_estimators = [1,2,3,4,5,6,7,8]\n",
                "# scores2 = dict()\n",
                "# i = 0\n",
                "# for e in n_estimators:\n",
                "#     rf = RandomForestClassifier(n_estimators = e, criterion = 'gini', random_state = 1738)\n",
                "#     rf.fit(X_train, y_train)\n",
                "#     scores2[i] = {'recall':recall_score(y_test, rf.predict(X_test)), 'trees' :e}\n",
                "#     i+=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# pd.DataFrame(scores2).T"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "![recallScores2](.\/assets\/recallScores4.PNG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We are focussing on Gini random forests with trees between 1 and 8. There is not enough consistency in the results to say more trees are better or worse. However, it might be tempting to try to tune-and-tune hyperparameters to increase scores. In many cases (as in the example above), mostly hyperparameter tuning results in not creating a better model, but it does a better job of predicting the test set."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}