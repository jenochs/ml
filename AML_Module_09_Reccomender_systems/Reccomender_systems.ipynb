{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "#  Recommender Systems\n",
                "\n",
                "\n",
                "**Author: Carleton Smith**\n",
                "\n",
                "**Reviewer: Jessica Cervi**\n",
                "\n",
                "**Expected time = 2.5 hours**\n",
                "\n",
                "**Total points = 90 points**\n",
                " \n",
                "## Assignment Overview\n",
                "\n",
                "In this assignment, we will work on recommender systems. Recommender systems provide a non-parametric comparison between items. They are fundamental in analyzing how individuals can be served.\n",
                "This project consists of 4 parts:  \n",
                " \n",
                " - General Familiarization with the data.\n",
                " - Mathematical foundations of recommender systems and simple examples about them.\n",
                " - Execution of methods on the data.\n",
                " - Short introduction to the `Surprise` package.   \n",
                " \n",
                "All the methods used below should be familiar from the material from this week's lectures. Except for the singular value decomposition (SVD) and the `Surprise` package, we will review some main concepts before demonstration.\n",
                "\n",
                "The general goal of this project is, given a collection of users, items, and user reviews of the items, predict what score a user would assign to an item they have yet to review.  \n",
                "\n",
                "We will be working with a synthetic review dataset, modeled on reviews from Amazon. To demonstrate the techniques, in all our examples, we will work only with a smaller portion of the made-up data.\n",
                "\n",
                "This assignment is designed to build your familiarity and comfort in coding in Python. It will also help you review the key topics from each module. As you progress through the assignment, answers to the questions will get increasingly complex. You must adopt a data scientist's mindset when completing this assignment. Remember to run your code from each cell before submitting your assignment. Running your code beforehand will notify you of errors and giving you a chance to fix your errors before submitting it. You should view your Vocareum submission as if you are delivering a final project to your manager or client. \n",
                "\n",
                "***Vocareum Tips***\n",
                "- Do not add arguments or options to functions unless asked specifically. This will cause an error in Vocareum.\n",
                "- Do not use a library unless you are explicitly asked in the question. \n",
                "- You can download the Grading Report after submitting the assignment. It will include the feedback and hints on incorrect questions. \n",
                "\n",
                "\n",
                "\n",
                "\n",
                "### Learning Objectives\n",
                "- Understand mathematical foundations of recommender systems\n",
                "- Translate a mathematical algorithm into code\n",
                "- Determine similarity between items by using Euclidean distance, Pearson's coorelation-coefficient, and cosine similiarty \n",
                "- Predict item recommendations using similarity scores \n",
                "- Understand utilization complexity to noramlize user ratings \n",
                "- Make item recommendations using singular value decomposition (SVD) \n",
                "- Implement SVD using the `surprise` package\n",
                "\n",
                "\n",
                "## Index: \n",
                "\n",
                "###  Recommender Systems\n",
                "\n",
                "+ [Question 01](#q1)\n",
                "+ [Question 02](#q2)\n",
                "+ [Question 03](#q3)\n",
                "+ [Question 04](#q4)\n",
                "+ [Question 05](#q5)\n",
                "+ [Question 06](#q6)\n",
                "+ [Question 07](#q7)\n",
                "+ [Question 08](#q8)\n",
                "+ [Question 09](#q9)\n",
                "+ [Question 10](#q10)\n",
                "+ [Question 11](#q11)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "#  Recommender Systems\n",
                "\n",
                "### Importing the dataset \n",
                "In the first part of this assignment, we will be using synthetic data modeled from Amazon reviews. A description of the review data and instructions to download the database [can be found here](https:\/\/s3.amazonaws.com\/amazon-reviews-pds\/readme.html).  \n",
                "\n",
                "We begin by importing the libraries we will use in this assignment.\n",
                "\n",
                "Next, we use the `pandas` `read_table` function to read the dataset. Finally, we display a sample of the data taken from Amazon."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import datetime\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_data_path = \"https:\/\/s3.amazonaws.com\/amazon-reviews-pds\/tsv\/sample_us.tsv\"\n",
                "\n",
                "rev_df = pd.read_csv(sample_data_path, sep='\\t')\n",
                "\n",
                "rev_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Looking at our raw data\n",
                "\n",
                "Although Natural Language Processing (NLP) might offer insight into the structure of reviews, for this assignment, we are only interested in the customers (`customer_id`), the products (`product_id`), and the scores (`star_rating`) that each customer assigned to a particular product.\n",
                "\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q1'><\/a>\n",
                "\n",
                "### Question 1:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Extract a subset from our dataframe `rev_df` containing only the columns `customer_id`,`product_id` and `star_rating`. Assign the new dataframe to `rev_df`. Finally, rename the column `star_rating` to `score`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 01",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's have a look at our new dataframe!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rev_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Although this is not strictly necessary, we can modify the values in columns customer_id and product_id to make them a little easier to read.  \n",
                "\n",
                "We will do so by building two dictionaries: one for `customer_id` and the other one for `product_id` in the following way.\n",
                "\n",
                "Let the keys for your dictionary be all the *n unique* values of `customer_id`. Rewrite such values to read \"R\" followed by a number ###, from 0 to n, such that each unique key is mapped to a unique string of the format `R###`. We do the same for the products, but using \"P\" as a prefix instead."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "rID_dict = {rID:'R'+ str(idx) for idx, rID in enumerate(rev_df['customer_id'].unique()) }\n",
                "pID_dict = {pID:'P'+ str(idx) for idx, pID in enumerate(rev_df['product_id'].unique()) }\n",
                "\n",
                "\n",
                "### Checking the values in the dictionaries below for products.\n",
                "for k in list(pID_dict.keys())[:5]:\n",
                "    print(k, \":\",pID_dict[k])\n",
                "print(\"length: \",len(pID_dict))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id='q2'><\/a>\n",
                "\n",
                "### Question 2:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "\n",
                "Replace the values in the column `product_id` in the dataframe `ref_df` with the entries in the dictionary `pID_dict` created above. Do the same with the `customer_id` column, but, this time, use the entries in `pID_dict`.\n",
                "\n",
                "**HINT:** You can achieve this by using the `loc` and `map` functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 02",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's have a look at our new dataframe!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rev_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"Exploratory Data Analysis\"><\/a>\n",
                "### Exploratory Data Analysis (EDA)\n",
                "Having gone through the process of cleaning and analyzing the data, we will load a more extensive synthetic dataset and perform some light EDA to look at the distributions of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Reading the data\n",
                "synth_data_path = \".\/data\/synthetic_reviews.csv\"\n",
                "\n",
                "rev_df = pd.read_csv(synth_data_path)\n",
                "rev_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "First, we visualize how many products got a score of 5, 4, 3, 2, or 1. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "rev_df['score'].value_counts().plot(kind = 'bar');"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Next, we count how many products received a specific score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "rev_df['score'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We notice that there is an interesting preponderance of products with score 5. \n",
                "\n",
                "We continue by ranking the product from the ones that had the most reviews to the ones that had the least. We display the first 15 and the last 5 rows of this ranking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print(\"Reviews per product, top and bottom reviewed\\n\")\n",
                "#Display first 15 rows\n",
                "print(rev_df['productID'].value_counts()[:15])\n",
                "#Display last 5 rows\n",
                "print(rev_df['productID'].value_counts()[-5:])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Below, we visualize the ranking defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "product_w_n_reviews = rev_df['productID'].value_counts().value_counts()\n",
                "plt.figure(figsize = (10,7))\n",
                "plt.scatter(product_w_n_reviews.index, product_w_n_reviews)\n",
                "plt.xlabel(\"Number of Reviews\", fontsize = 16)\n",
                "plt.ylabel(\"Number of Products\", fontsize = 16);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The above graph seems to be on a log-normal scale. \n",
                "\n",
                "In reality, the graph displayed has the shape of a \"hollow curve\". The log-normal appearance is an artifact of the data synthesis.\n",
                "\n",
                "We will continue our EDA by ranking which customers gave the most and least number of reviews."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print(\"Reviews per reviewer, top and bottom reviewers\\n\")\n",
                "print(rev_df['reviewerID'].value_counts()[:15])\n",
                "print(rev_df['reviewerID'].value_counts()[-5:])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Again, we visualize the ranking defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "product_w_n_reviews = rev_df['reviewerID'].value_counts().value_counts()\n",
                "plt.figure(figsize = (10,7))\n",
                "plt.scatter(product_w_n_reviews.index, product_w_n_reviews)\n",
                "plt.xlabel(\"Number of Reviews\", fontsize = 16)\n",
                "plt.ylabel(\"Number of Users\", fontsize = 16);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "As expected, most products are only reviewed a few times, most users only submit a few reviews, and very few users have submitted many reviews. \n",
                "\n",
                "Again. the above graph has the shape of a \"hollow curve\"."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"simple\"><\/a>\n",
                "### Functioning of Recommender Systems\n",
                "\n",
                "Before tackling our extensive synthetic data, we will use a simpler dataset to demonstrate the functioning of recommender systems.  \n",
                "\n",
                "Below we have a set of rankings of six musicians made by six individuals.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "example_path = \".\/data\/example.csv\"\n",
                "ex = pd.read_csv(example_path, index_col = 0)\n",
                "ex"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note that the value \"0\" in the rows above denotes the absence of ranking - **NOT** an extremely poor ranking.  \n",
                "\n",
                "To determine which product to recommend, we can compute the similarity scores between products. Similarity scores can be computed in three different ways:\n",
                "\n",
                "- the Euclidean distance,\n",
                "- the Pearson's correlation coefficient,\n",
                "- and the cosine similarity score. \n",
                "\n",
                "To compare these scores we will normalize each to range between 0 and 1.  \n",
                "To simplify our analysis, we will use a subset of our example DataFrame:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ex_hand = ex.iloc[:3,-3:]\n",
                "ex_hand"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Euclidean Distance\n",
                "\n",
                "The Euclidean distance between point $i =(a_i, b_i, \\dots, n_i)$ and point $j= (a_j, b_j, \\dots, n_j)$ is given by\n",
                "\n",
                "$$\\sqrt{(a_j-a_i)^2+(b_j-b_i)^2+...+(n_j-n_i)^2}$$  \n",
                "\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q3'><\/a>\n",
                "\n",
                "### Question 3:\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Calculate the Euclidean distance between Brahms and Wagner in the `ex_hand` DataFrame. \n",
                "\n",
                "\n",
                "Assign the computed distance as a float to the variable ans2. Make sure that the answer is accurate to 3 decimal places.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "ans2 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 03",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "To normalize the Euclidean distance between 0 and 1, we can use the following formula that relates \"distance\" to \"similarity\"\n",
                "\n",
                "$$\\text{similarity} =\\frac1{1+\\text{distance}}.$$\n",
                "\n",
                "For example, a distance of 0 corresponds to a similarity of 1, and a very large distance (e.g., $\\infty$) corresponds to a similarity of 0.  \n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id='q4'><\/a>\n",
                "\n",
                "### Question 4:\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Define a  function called `e_sim` that accepts two `pandas` series as arguments.\n",
                "\n",
                "Your function should return the Euclidean similarity score between the two series. Make sure that the answer is accurate to 3 decimal places.\n",
                "\n",
                "For this question, you will need to use the attribute `np.linalg.norm()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "def e_sim(ser1, ser2):\n",
                "    \"\"\"\n",
                "    Given two Pandas series, compute the euclidean similarity score;\n",
                "        1 \/ 1+euclidean distance\n",
                "        \n",
                "    Positional Arguments --\n",
                "        ser1: a Pandas Series of length n\n",
                "        ser2: a Pandas Series of length n\n",
                "    \n",
                "    Example --\n",
                "        ser1 = ex_hand.iloc[:,0]\n",
                "        ser2 = ex_hand.iloc[:,1]\n",
                "        print(e_sim(ser1, ser2)) #--> 0.28989794855663564\n",
                "    \"\"\"\n",
                "    return\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 04",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Pearson's Correlation Coefficient\n",
                "\n",
                "The Pearson's correlation coefficient $\\rho$ takes values from -1 to 1. Therefore, to normalize it into a difference score between 0 and 1, we need to reduce that range by half (i.e., divide the range by two) to increase the minimum score to 0, and add .5:  \n",
                "\n",
                "$$\\frac12 + \\frac{\\rho_{xy}}2$$  \n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id=\"q5\"><\/a>\n",
                "### Question 05\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Define a  function called `p_sim` that accepts two `pandas` series as arguments.\n",
                "\n",
                "Your function should return the Pearson correlation coefficient between the two series. Make sure that the answer is accurate to 3 decimal places.\n",
                "\n",
                "For this question you will need to use the attribute `np.corrcoef()`.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "def p_sim(ser1, ser2):\n",
                "    \"\"\"\n",
                "    Given two Pandas series, compute the Pearson correlation coefficient;\n",
                "    \"\"\"\n",
                "    return\n",
                "\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 05",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Cosine Similarity\n",
                "\n",
                "The cosine similarity calculates the cosine of the angle between two vectors normalizing it between 0 and 1. \n",
                "\n",
                "The cosine similarity score is given by the following formula\n",
                "\n",
                "$$cos(\\theta) = \\frac{S1\\cdot S2}{||S1||\\cdot||S2||},$$\n",
                " \n",
                " where $S1$ and $S2$ are the two vectors considered, and $||\\cdot||$ represents the magnitude of each vector.\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id=\"q6\"><\/a>\n",
                "### Question 06\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Define a  function called `c_sim` that accepts two `pandas` series as arguments.\n",
                "\n",
                "Your function should return the cosine similarity between the two series. Make sure that the answer is accurate to 3 decimal places.\n",
                "\n",
                "For this question, you will need to use the attribute `np.linalg.norm()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "def c_sim(ser1, ser2):\n",
                "    \"\"\"\n",
                "    Function to compute the cosine similarity\n",
                "    \"\"\"\n",
                "    \n",
                "    return \n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 06",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "At this point, we have defined three functions for calculating similarity between two vectors.  \n",
                "\n",
                "- e_sim: for the Euclidean similarity \n",
                "- p_sim: for the Pearson correlation coefficient similarity\n",
                "- c_sim: for the cosine similarity\n",
                " "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Now, let's calculate each of the three similarity scores for each pair of musicians in the `ex` DataFrame.  \n",
                "\n",
                "Let's recall what the DataFrame `ex` looks like."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ex"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The function we will build must take into account that not all users have rated all musicians.\n",
                "\n",
                "So, for example, when comparing \"Mozart\" and \"Bach\", we must disregard the observations from \"Abel\" and \"Baker\", respectively.  \n",
                "\n",
                "This can be done by reading the value \"0\" as to be \"less than 1\", and *not* as the lack of information which it actually represents.  \n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id=\"q7\"><\/a>\n",
                "### Question 07\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Define a  function called `drop_val` that accepts the following  arguments:\n",
                "\n",
                "- A `pandas` DataFrame.\n",
                "- A numeric variable named `to_drop`.\n",
                "\n",
                "Your function should drop all the rows that have the value contained in `to_drop` in any column, and should return the DataFrame without the rows that have been dropped.\n",
                "\n",
                "For example, if we pass the DataFrame `ex` containing all rows but only the columns corresponding to \"Mozart\" and \"Bach\", and we set  'to_drop=5', our function should return \"Abel\", \"Erik\", and \"Frank\" rows with all the original columns. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "def drop_val (df, to_drop):\n",
                "    \n",
                "    \"\"\"\n",
                "    Drop rows from the DataFrame containing the specified values\n",
                "    \n",
                "    Positional Arguments --\n",
                "        df: a Pandas DataFrame\n",
                "        to_drop: a value found in some rows of df\n",
                "    \n",
                "    Example --\n",
                "        \n",
                "        df = ex.loc[:,\"Mozart\":\"Bach]\n",
                "        to_drop = 5\n",
                "        print(drop_val(df,to_drop)) # -->          Mozart  Bach\n",
                "                                            Abel        0     1\n",
                "                                            Erik        3     3\n",
                "                                            Frank       2     2   \n",
                "    \"\"\"\n",
                "    return\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 07",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The cell below defines a function \"drop_rows_with_zeros\" that takes a DataFrame with two columns and returns a DataFrame where all the rows that contain a value of 0 have been removed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Defining drop_rows_with_zeros\n",
                "\n",
                "def drop_rows_with_zeros(df):\n",
                "    keep = np.intersect1d( df.iloc[:,0].to_numpy().nonzero(), df.iloc[:,1].to_numpy().nonzero())\n",
                "    \n",
                "    return df.iloc[keep,:]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Comparison of Similarity Scores\n",
                "\n",
                "Below, we will compare the similarity scores for each combination of musicians. \n",
                "\n",
                "First, we find all the possible pairs of musicians:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import itertools\n",
                "for c in itertools.combinations(ex.columns,2):\n",
                "    print(c)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Each tuple can be used as a subset in the DataFrame. For example, the subset for Mozart and Bach is given by:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ex[list(('Mozart', 'Bach'))]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Next, we define a first dictionary that has as keys the pairs of musicians being compared.\n",
                "\n",
                "In a second dictionary, we define the similarity scores, \"Euclid\", \"Pearson\", and \"Cosine\",  corresponding to each pair of musicians."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "sim_scores = dict()\n",
                "\n",
                "for c in itertools.combinations(ex.columns, 2):\n",
                "    df = drop_rows_with_zeros(ex[list(c)])\n",
                "    ser1 = df.iloc[:,0]\n",
                "    ser2 = df.iloc[:,1]\n",
                "    scores = {\"Euclid\":e_sim(ser1, ser2), \"Pearson\":p_sim(ser1,ser2), \"Cosine\":c_sim(ser1,ser2)}\n",
                "    key =\", \".join(c)\n",
                "    sim_scores[key] = scores\n",
                "    \n",
                "sims = pd.DataFrame.from_dict(sim_scores,orient = \"index\")\n",
                "sims"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The similarity scores can be visualized as follow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Note: x and y scales are not consistent in this visualization\n",
                "sns.pairplot(sims );"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Visualization with consistent x and y scales using `matplotlib`\n",
                "plt.figure(figsize = (12,6))\n",
                "for i, cols in enumerate([('Euclid','Pearson'), (\"Euclid\",\"Cosine\"),(\"Pearson\",\"Cosine\")]):\n",
                "    plt.subplot(1,3,i+1)\n",
                "    \n",
                "    plt.scatter(sims[cols[0]], sims[cols[1]])\n",
                "    \n",
                "    plt.xlabel(cols[0], fontsize = 14); plt.ylabel(cols[1], fontsize = 14)\n",
                "    plt.xlim(0,1); plt.ylim(0,1)\n",
                "    \n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"sim-note\"><\/a>\n",
                "### Differences in Similarity Scores\n",
                "\n",
                "\n",
                "As we can see from the graphs above, it is possible to visualize a range of similarity scores given different techniques. These similarity scores will majorly impact how a recommender system performs. \n",
                "\n",
                "Refer to the lectures for the particular impacts and strengths of the different similarity calculations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = 'pred'><\/a>\n",
                "### Predicting Unknown Scores\n",
                "\n",
                "Assume that we don't know the score that Abel gave to Mozart. To do so, we must take into account that Mozart has a similarity score in relation to all the other musicians.\n",
                "\n",
                "Similarly, Abel has given a score to all the other musicians.  \n",
                "\n",
                "Therefore, Abel's predicted score for Mozart will be given by: the **sum** of Abel's score for every other musician **times** that musician's similarity score with respect to Mozart, **divided by** the sum of similarity scores.  \n",
                "\n",
                "For example, we can predict Abel's score for Mozart by computing\n",
                "\n",
                "$$\\frac{\\sum_{ mus = Bach}^{Liszt}A_{mus}*\\text{simScore}(\\text{Mozart, mus})}{\\sum_{mus = Bach}^{Liszt}\\text{simScore}{\\text{(Mozart, mus)}}}$$ \n",
                "\n",
                "The commands below compute the similarity scores for Mozart."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "drop_rows_with_zeros(ex.iloc[:, :6])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "mozSimScores = {}\n",
                "for mus in ex.columns[1:]:\n",
                "    no_zeros = drop_rows_with_zeros(ex[['Mozart', mus]])\n",
                "    \n",
                "    mozSimScores[mus] = round(p_sim(no_zeros.iloc[:,0], no_zeros.iloc[:,1]),2)\n",
                "\n",
                "print(mozSimScores)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Back to top](#Index:) \n",
                "<a id=\"q8\"><\/a>\n",
                "### Question 08\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Given the similarity scores calculated and stored in `mozSimScores`, use the above formula to predict Abel's score for Mozart. Assign your result to the variable `ans6`. Make sure the answer is accurate to 3 decimal places.\n",
                "\n",
                "*Hint*: Use the rounded score computed above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "###  YOUR SOLUTION HERE\n",
                "\n",
                "ans6 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 08",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We observe that, although many other users gave Mozart high scores, because Abel appears to be less generous in his reviews, his predicted score for Mozart is fairly low. \n",
                "\n",
                "The function defined below predicts an unknown score based on the formula above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Creating a function to create predictions in the manner described above.\n",
                "### Note: \"user\" is a row, and \"item\" is a column in the df.\n",
                "### simFunc defaults to p_sim\n",
                "\n",
                "def scorePred(df, user, item, simFunc = p_sim, rev_items = None):\n",
                "    \"\"\"\n",
                "    Positional Arguments --\n",
                "        df: Pandas DataFrame\n",
                "        user: Row-index in df\n",
                "        item: Column-index in df\n",
                "        simFunc: a similarity function (e_sim, p_sim, or c_sim)\n",
                "        rev_items: For larger dfs, specifies all items reviewed by \"user\"\n",
                "    \"\"\"\n",
                "    # Check to see if user has already scored item\n",
                "    if df.loc[user,item] > 0:\n",
                "        return \"Already rated a \"+str(df.loc[user,item])\n",
                "    \n",
                "    # rev_items used for larger DataFrame,\n",
                "    # when you have all the items a particular user has reviewed already\n",
                "    # otherwise, if \"None\" (if statement below)\n",
                "    # take all other items other than item to predict\n",
                "    if not rev_items:\n",
                "        rev_items = set(df.columns)\n",
                "        rev_items.remove(item)\n",
                "    \n",
                "    sim_total, user_sim_total = 0,0\n",
                "    \n",
                "    for other_item in rev_items:\n",
                "        user_score_other_item = df.loc[user, other_item] # grab user score\n",
                "        \n",
                "        if user_score_other_item == 0:\n",
                "            print(\"no user score\")\n",
                "            continue\n",
                "        \n",
                "        # Use function built above to drop all other users with \"other_item\" score of \"0\"\n",
                "        no_zeros = drop_rows_with_zeros(df[[item, other_item]]) \n",
                "        sh = no_zeros.shape\n",
                "        \n",
                "        # If no other users, move to next item\n",
                "        if sh[0] == 0:\n",
                "            continue\n",
                "            \n",
                "        #print(no_zeros.shape)\n",
                "        \n",
                "        # calculate similarity score using non-zero information. \n",
                "        ser1 = no_zeros.iloc[:,0]\n",
                "        ser2 = no_zeros.iloc[:,1]\n",
                "        # print(ser1, ser2)\n",
                "        ss = simFunc(no_zeros.iloc[:,0], no_zeros.iloc[:,1])\n",
                "        # print(ss, user_score_other_item)\n",
                "        \n",
                "        # add up sim total and weighted sim total\n",
                "        sim_total += ss\n",
                "        user_sim_total += user_score_other_item * ss\n",
                "\n",
                "        \n",
                "    if sim_total == 0:\n",
                "        return 0\n",
                "    \n",
                "    else:\n",
                "        return user_sim_total \/ sim_total"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ex"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Use the cells below to compute the unknown score for different cases using the function `scorePred` defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scorePred(ex, 'Baker', 'Bach')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"ret\"><\/a>\n",
                "### Returning to the Data\n",
                "Let's go back to the Amazon rating DataFrame."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "rev_df.head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We observe that now the data does not conform to the two-dimensional n-by-p matrix that we have been using. Therefore, we need to manipulate our data. \n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id=\"q9\"><\/a>\n",
                "### Question 09\n",
                "\n",
                "*10 points*\n",
                "\n",
                "Use the  `Pandas` built-in `pivot()` attribute to reshape our data. Set `reviewerID` as index and use `productID` to rename the columns. Assign the new dataframe to `reshaped_reviews`. Next, replace all the NaN values with zeroes. Finally, use `droplevel()` on the columns to remove the artifact of the pivot function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "\n",
                "###  YOUR SOLUTION HERE\n",
                "\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 09",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's have a look at our reshaped dataframe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print(\"shape: \", reshaped_reviews.shape)\n",
                "reshaped_reviews.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "It should be clear from the output above that the majority of the entries corresponding to a certain pair of customer and product are now empty. Thus, when trying to provide recommendations, it will not be possible to predict scores for every  combination of customer and product. In fact, to predict scores, we require a certain amount of overlap between the data.\n",
                "\n",
                "Below predictions are created for our reviewer called \"R0\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### First, find the products that 'R0' has reviewed.\n",
                "### These are the products that will be used for creating similarity scores.\n",
                "\n",
                "r0 = reshaped_reviews.loc[\"R0\", :]\n",
                "# numpy function returns all indexes that are not \"0\"\n",
                "r0_nonzero = r0.to_numpy().nonzero()\n",
                "# collect names of reviewed products\n",
                "r0_rev_prods = list(r0.iloc[r0_nonzero].index) \n",
                "print(len(r0_rev_prods))\n",
                "r0_rev_prods[:5]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we create a list containing the product that have not been reviewed by R0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Creating a list of products not reviewed by R0\n",
                "\n",
                "# return list of all prods not in the \"reviewed\" list\n",
                "r0_not_rev = np.setdiff1d(reshaped_reviews.columns, r0_rev_prods) \n",
                "\n",
                "print(len(r0_not_rev))\n",
                "r0_not_rev"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The commands below require too much processing for Vocareum. \n",
                "```python\n",
                "### predict scores for products not yet reviewed by R0, using function built above: `scorePred`\n",
                "### cosine similarity used because if a product all has only one value of review (e.g. all 5s)\n",
                "### then the standard_deviation is 0 and the correlation coefficient is not calculable\n",
                "\n",
                "preds = {}\n",
                "for item in r0_not_rev:\n",
                "   preds[item] = scorePred(reshaped_reviews, 'R0', item, simFunc = c_sim, rev_items = r0_rev_prods)\n",
                "\n",
                "pd.Series(preds).sort_values(ascending = False).head(10)\n",
                "```\n",
                "We simply display the output below:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "```\n",
                "P470     5.0\n",
                "P2342    5.0\n",
                "P4839    5.0\n",
                "P4796    5.0\n",
                "P2703    5.0\n",
                "P4800    5.0\n",
                "P615     5.0\n",
                "P4806    5.0\n",
                "P2699    5.0\n",
                "P1533    5.0\n",
                "dtype: float64\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"util\"><\/a>\n",
                "### Utilization Complexities\n",
                "\n",
                "Certainly, if  a product is likely to score a \"5\", then that product should be recommended. However, because we are dealing with very sparse data, the confidence in our predictions will vary between each product.\n",
                "\n",
                "[Back to top](#Index:) \n",
                "<a id=\"q10\"><\/a>\n",
                "### Question 10\n",
                "\n",
                "*5 points*\n",
                "\n",
                "Consider 3 products: `A`, `B`, and `X`. Assume that `userN` has ranked both products `A` and `B` with a score of 5. Assume that `user1` has ranked products `A` and `X` both with a score 3 and assume that `user2` has ranked products `B` and `X` with a score 2.\n",
                "\n",
                "What will be the similarity score between product `A` and product `X`? Assign the result rounded to 2 decimal places the variable ans7a.\n",
                "\n",
                "What will be the similarity score between product `B` and product `X`? Assign the result rounded to 2 decimal places the variable ans7b.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "ans7a = None\n",
                "ans7b = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 10",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "It is important to note that we could have run into other possible scenarios: high similarity scores because of few overlapping reviews, or a high-user score for the user who is being predicted for.  \n",
                "\n",
                "<a id = \"svd\"><\/a>\n",
                "### Singular Value Decomposition (SVD)\n",
                "\n",
                "We can deal with the sparsity of data and, at the same time, increase the speed of our algorithm,  by using Singular Value Decomposition (SVD). SVD is a technique that reduces the dimensionality of functions by \"capturing\" a majority of the information present in a dataset in a smaller number of variables.  \n",
                "\n",
                "SVD relies upon some straight-forward linear algebra that is worth understanding. The main concepts have been covered in the lectures. Here are some more insightful resources about SVD.  \n",
                "\n",
                "[Here is a nice introduction.](https:\/\/machinelearningmastery.com\/singular-value-decomposition-for-machine-learning\/)  \n",
                "\n",
                "[Below, we will use `numpy's` implementation of SVD](https:\/\/docs.scipy.org\/doc\/numpy-1.14.0\/reference\/generated\/numpy.linalg.svd.html)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We have learned that the quantity $\\Sigma ^2$ describes the variance of each vector. The plot below displays the rate of the variance given by n vectors as a function of the total number of products.\n",
                "\n",
                "![svd](.\/assets\/svd.PNG)\n",
                "\n",
                "We notice that about 1700 of the decomposed vectors will give around 80% of the variance in the data. Computationally, this will make the calculations much faster: in fact, considering only 1\/3 of the vectors will yield 80% of the value. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The commands below take too long to run for Vocareum. \n",
                "```python\n",
                "# Perform SVD\n",
                "u, sigma, _ = np.linalg.svd(reshaped_reviews)\n",
                "\n",
                "# Create function to decompose DataFrame\n",
                "def return_svd(df , u, sigma, n):\n",
                "   sigN = np.mat(np.eye(n) * sigma[:n]) #arrange Sig4 into a diagonal matrix\n",
                "   n_svd_vectors = np.dot(df.T, np.dot(u[:,:n] , sigN.I))  #create transformed items\n",
                "   return pd.DataFrame(n_svd_vectors).T\n",
                "\n",
                "# use function to create decomposed DataFrame\n",
                "svd_df = return_svd(reshaped_reviews, u, sigma, 1700)\n",
                "svd_df.columns = reshaped_reviews.columns\n",
                "\n",
                "# Save DataFrame\n",
                "\n",
                "svd_df.to_csv(\"svd_df.csv\")\n",
                "```\n",
                "The results are loaded below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "svd_df = pd.read_csv(\".\/data\/svd_df.csv\", index_col = 0)\n",
                "svd_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "As `svd_df` indicates, the svd vectors correspond to different items. The calculation for the recommendation will be the same, but will be done by using these new values.  \n",
                "\n",
                "For example, to predict the score that reviewer \"R0\" would give to  the product 'P1' (Remember \"R0\" already reviewed \"P0\") we must follow the following steps:  \n",
                "\n",
                "1. Find the products that R0 scored.\n",
                "2. Find the similarity between those scored products and \"P1\".\n",
                "3. Multiply those similarity scores by the scores from R0.\n",
                "4. Divide by sum of similarity scores.  \n",
                "\n",
                "The downside of SVD is that it must be performed before the calculations, and, as was seen above, such computations can take some time. In fact, in practice, SVD would need to be performed each time a new review is added.\n",
                "\n",
                "The following function computes the prediction scores from the `svd_df` DataFrame."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Creating a function to create predictions using the SVD_df\n",
                "### Note: \"user\" is a row, and \"item\" is a column in the df, and a column in svd_df.\n",
                "### simFunc defaults to p_sim\n",
                "\n",
                "def scorePredSVD(df, user, item, svd_df, simFunc = p_sim, rev_items = None):\n",
                "    \n",
                "    # Check to see if user has already scored item\n",
                "    if df.loc[user,item] > 0:\n",
                "        return \"Already rated a \"+str(df.loc[user,item])\n",
                "    \n",
                "    # Code below should be familiar from \"scorePred\" defined above\n",
                "    if not rev_items:\n",
                "        rev_items = set(df.columns)\n",
                "        rev_items.remove(item)\n",
                "    \n",
                "    sim_total, user_sim_total = 0,0\n",
                "    \n",
                "    for other_item in rev_items:\n",
                "        user_score_other_item = df.loc[user, other_item]\n",
                "        \n",
                "        if user_score_other_item == 0:\n",
                "            print(\"no user score\")\n",
                "            continue\n",
                "            \n",
                "        ser1 = svd_df.loc[:,item]\n",
                "        ser2 = svd_df.loc[:,other_item]\n",
                "        # print(ser1, ser2)\n",
                "        ss = simFunc(ser1, ser2)\n",
                "        # print(ss, user_score_other_item)\n",
                "        sim_total += ss\n",
                "        user_sim_total += user_score_other_item * ss\n",
                "\n",
                "        \n",
                "    if sim_total == 0:\n",
                "        return 0\n",
                "    \n",
                "    else:\n",
                "        return user_sim_total \/ sim_total"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The commands below predict  the scores for products not yet reviewed by R0, using the function built above: scorePred.\n",
                "We use the cosine similarity because if a product has only one value of review (e.g. all 5s), then the standard deviation is 0 and the correlation coefficient is not calculable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "\n",
                "SVDpreds = {}\n",
                "for item in r0_not_rev:\n",
                "    SVDpreds[item] = scorePredSVD(reshaped_reviews, 'R0', item, svd_df, simFunc = c_sim, rev_items = r0_rev_prods)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.Series(SVDpreds).sort_values(ascending = False).head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id=\"q11\"><\/a>\n",
                "[Back to top](#Index:) \n",
                "### Question 11\n",
                "\n",
                "*5 points*\n",
                "\n",
                "SVD is a kind of:\n",
                "- a) Variance reduction\n",
                "- b) Special type of array in Python\n",
                "- c) Dimensionality reduction\n",
                "- d) Description of central tendency\n",
                "\n",
                "Assign the character associated with your choice as a string to the variable ans8."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "ans8 = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 11",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<a id = \"surprise\"><\/a>\n",
                "### Surprise - Python Package\n",
                "[`Surprise`](http:\/\/surpriselib.com) is a Python package which implements a number of tools for building and testing recommender systems. The documentation can be found [here](https:\/\/surprise.readthedocs.io\/en\/stable\/).\n",
                "\n",
                "**THE FOLLOWING CODE WILL NOT RUN ON VOCAREUM. WE JUST PROVIDE EXAMPLES IN CASE YOU CHOOSE TO USE `SURPRISE` IN YOUR OWN ENVIRONMENT**  \n",
                "\n",
                "\n",
                "To install surprise, run:  \n",
                "\n",
                "`conda install -c conda-forge scikit-surprise`  \n",
                "\n",
                "in the Anaconda Prompt. After the installation, you might have to reinstall or update scipy, and restart Kernel by doing\n",
                "\n",
                "`conda install -c anaconda scipy`  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Below is [example code from the surprise documentation](https:\/\/surprise.readthedocs.io\/en\/stable\/getting_started.html#)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# from surprise import SVD\n",
                "# from surprise import Dataset\n",
                "# from surprise.model_selection import cross_validate\n",
                "\n",
                "\n",
                "# # Load the movielens-100k dataset (download it if needed),\n",
                "# data = Dataset.load_builtin('ml-100k')\n",
                "\n",
                "# # We'll use the famous SVD algorithm.\n",
                "# algo = SVD()\n",
                "\n",
                "# # Run 5-fold cross-validation and print results\n",
                "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "[Loading in a df](https:\/\/surprise.readthedocs.io\/en\/stable\/dataset.html?highlight=pandas#surprise.dataset.Dataset.load_from_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# import os\n",
                "# from surprise import BaselineOnly\n",
                "# from surprise import Reader\n",
                "\n",
                "# # when using a df to load in data, the columns must be:\n",
                "# # user, product, rating, in that order\n",
                "# # a reader must be defined to describe the rating_scale\n",
                "# reader = Reader(rating_scale=(0,5))\n",
                "\n",
                "# data = Dataset.load_from_df(rev_df, reader=reader)\n",
                "\n",
                "# # We can now use this dataset as we please, e.g. calling cross_validate\n",
                "# cross_validate(BaselineOnly(), data, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### One final note: \n",
                "\n",
                "This project has based its recommendations of comparing the similarity of different *items*.  Using the same technique, it is also possible to calculate the similarity of *users*. The reason why *items* is usually the default choice is that there are usually fewer items than users. This decreases the number of similarity calculations required. \n",
                "\n",
                "For example, in our data, we had roughly 3.5k items and 5.5k users. When using a complete dataset from a specific source, this difference will be more significant."
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "formats": "ipynb,md"
        },
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}